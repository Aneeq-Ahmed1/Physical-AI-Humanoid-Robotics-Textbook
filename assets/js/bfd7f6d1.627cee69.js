"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[801],{10:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"vla-llm/index","title":"Chapter 04: VLA and LLM Integration","description":"This chapter covers the integration of Vision-Language-Action (VLA) models and Large Language Models (LLMs) in robotic systems.","source":"@site/docs/04-vla-llm/index.md","sourceDirName":"04-vla-llm","slug":"/vla-llm/","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/vla-llm/","draft":false,"unlisted":false,"editUrl":"https://github.com/aneeq-ai/Humanoid-Robotics-Textbook/edit/master/my-website/docs/04-vla-llm/index.md","tags":[],"version":"current","frontMatter":{},"sidebar":"textbookSidebar","previous":{"title":"Chapter 03: NVIDIA Isaac - Navigation and Manipulation","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/nvidia-isaac/navigation-manipulation"},"next":{"title":"Chapter 04: Whisper Integration","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/vla-llm/whisper-integration"}}');var o=t(4848),a=t(8453);const s={},r="Chapter 04: VLA and LLM Integration",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Coming Soon",id:"coming-soon",level:2}];function d(e){const n={h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"chapter-04-vla-and-llm-integration",children:"Chapter 04: VLA and LLM Integration"})}),"\n",(0,o.jsx)(n.p,{children:"This chapter covers the integration of Vision-Language-Action (VLA) models and Large Language Models (LLMs) in robotic systems."}),"\n",(0,o.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(n.p,{children:"By the end of this chapter, you will understand:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Vision-Language-Action model integration"}),"\n",(0,o.jsx)(n.li,{children:"LLM integration for task planning"}),"\n",(0,o.jsx)(n.li,{children:"Voice control systems for robots"}),"\n",(0,o.jsx)(n.li,{children:"Natural language processing for robotics"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"coming-soon",children:"Coming Soon"}),"\n",(0,o.jsx)(n.p,{children:"This chapter is under development and will be available soon."})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>r});var i=t(6540);const o={},a=i.createContext(o);function s(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);