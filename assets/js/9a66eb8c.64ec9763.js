"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[4071],{8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>l});var s=i(6540);const o={},t=s.createContext(o);function r(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),s.createElement(t.Provider,{value:n},e.children)}},9816:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"humanoid-robotics-textbook/spec","title":"Textbook Specification","description":"Feature Branch: physical-ai-humanoid-robotics-textbook-project","source":"@site/docs/humanoid-robotics-textbook/spec.md","sourceDirName":"humanoid-robotics-textbook","slug":"/humanoid-robotics-textbook/spec","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/humanoid-robotics-textbook/spec","draft":false,"unlisted":false,"editUrl":"https://github.com/Aneeq-Ahmed1/Physical-AI-Humanoid-Robotics-Textbook/edit/master/my-website/docs/humanoid-robotics-textbook/spec.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"Textbook Specification"}}');var o=i(4848),t=i(8453);const r={sidebar_position:1,title:"Textbook Specification"},l="Feature Specification: Physical AI & Humanoid Robotics Textbook Project",a={},c=[{value:"User Scenarios &amp; Testing <em>(mandatory)</em>",id:"user-scenarios--testing-mandatory",level:2},{value:"Module 1 - Master ROS 2 Architecture (Priority: P1)",id:"module-1---master-ros-2-architecture-priority-p1",level:3},{value:"Module 2 - Simulate Humanoid Robots (Priority: P1)",id:"module-2---simulate-humanoid-robots-priority-p1",level:3},{value:"Module 3 - Develop AI-Robot Brain in NVIDIA Isaac (Priority: P2)",id:"module-3---develop-ai-robot-brain-in-nvidia-isaac-priority-p2",level:3},{value:"Module 4 - Integrate LLMs for VLA (Priority: P2)",id:"module-4---integrate-llms-for-vla-priority-p2",level:3},{value:"Module 5 - Build Autonomous Simulated Humanoid (Priority: P3)",id:"module-5---build-autonomous-simulated-humanoid-priority-p3",level:3},{value:"Edge Cases",id:"edge-cases",level:3},{value:"Requirements <em>(mandatory)</em>",id:"requirements-mandatory",level:2},{value:"Functional Requirements",id:"functional-requirements",level:3},{value:"Clarifications",id:"clarifications",level:2},{value:"Session 2025-12-05",id:"session-2025-12-05",level:3},{value:"Key Entities <em>(include if feature involves data)</em>",id:"key-entities-include-if-feature-involves-data",level:3},{value:"Success Criteria <em>(mandatory)</em>",id:"success-criteria-mandatory",level:2},{value:"Measurable Outcomes",id:"measurable-outcomes",level:3}];function d(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"feature-specification-physical-ai--humanoid-robotics-textbook-project",children:"Feature Specification: Physical AI & Humanoid Robotics Textbook Project"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Feature Branch"}),": ",(0,o.jsx)(n.code,{children:"physical-ai-humanoid-robotics-textbook-project"}),"\r\n",(0,o.jsx)(n.strong,{children:"Created"}),": 2025-12-05\r\n",(0,o.jsx)(n.strong,{children:"Status"}),": Draft\r\n",(0,o.jsx)(n.strong,{children:"Input"}),': User description: "/sp.specify Physical AI & Humanoid Robotics Textbook Project']}),"\n",(0,o.jsx)(n.p,{children:'Project Overview:\r\nCreate an AI-native textbook on "Physical AI & Humanoid Robotics" for students and professionals learning embodied AI. The book should integrate ROS 2, Gazebo, NVIDIA Isaac, Unity, and LLM-powered robotics (VLA), emphasizing hands-on projects and capstone development.'}),"\n",(0,o.jsx)(n.p,{children:"Target Audience:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Graduate students, AI & robotics engineers"}),"\n",(0,o.jsx)(n.li,{children:"Educators in robotics or AI programs"}),"\n",(0,o.jsx)(n.li,{children:"Technically proficient learners with Python and robotics background"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Learning Goals:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Master ROS 2 architecture, nodes, topics, and services"}),"\n",(0,o.jsx)(n.li,{children:"Simulate humanoid robots using Gazebo & Unity"}),"\n",(0,o.jsx)(n.li,{children:"Develop perception, navigation, and manipulation pipelines in NVIDIA Isaac"}),"\n",(0,o.jsx)(n.li,{children:"Integrate LLMs for voice-command and task planning"}),"\n",(0,o.jsx)(n.li,{children:"Understand embodied AI principles and human-robot interaction"}),"\n",(0,o.jsx)(n.li,{children:"Build a fully autonomous simulated humanoid as a capstone"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Modules:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Robotic Nervous System (ROS 2)"}),"\n",(0,o.jsx)(n.li,{children:"Digital Twin Simulation (Gazebo & Unity)"}),"\n",(0,o.jsx)(n.li,{children:"AI-Robot Brain (NVIDIA Isaac)"}),"\n",(0,o.jsx)(n.li,{children:"Vision-Language-Action (LLM + Whisper integration)"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Technical Standards:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Accurate simulation with physics & sensor fidelity"}),"\n",(0,o.jsx)(n.li,{children:"Realistic perception and navigation pipelines"}),"\n",(0,o.jsx)(n.li,{children:"Hardware-software co-design for edge deployment (Jetson Orin)"}),"\n",(0,o.jsx)(n.li,{children:"Code & examples reproducible on local or cloud workstations"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Research & Development Workflow:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Iterative, hypothesis-driven development"}),"\n",(0,o.jsx)(n.li,{children:"Peer-reviewed references for all AI techniques"}),"\n",(0,o.jsx)(n.li,{children:"Knowledge transfer and documentation embedded in textbook"}),"\n",(0,o.jsx)(n.li,{children:"Continuous integration of simulation, real-world testing, and feedback"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Success Criteria:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:'Each module conta "'}),"\n"]}),"\n",(0,o.jsxs)(n.h2,{id:"user-scenarios--testing-mandatory",children:["User Scenarios & Testing ",(0,o.jsx)(n.em,{children:"(mandatory)"})]}),"\n",(0,o.jsx)(n.h3,{id:"module-1---master-ros-2-architecture-priority-p1",children:"Module 1 - Master ROS 2 Architecture (Priority: P1)"}),"\n",(0,o.jsx)(n.p,{children:"Learn and master the fundamental concepts of ROS 2, including nodes, topics, and services, essential for building robot control systems."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Why this priority"}),": ROS 2 is foundational for all subsequent robotics development in the book."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Independent Test"}),": User can successfully implement and run basic ROS 2 publisher-subscriber examples and service calls."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Acceptance Scenarios"}),":"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Given"})," a ROS 2 environment is set up, ",(0,o.jsx)(n.strong,{children:"When"})," the user follows the tutorial for creating a publisher node, ",(0,o.jsx)(n.strong,{children:"Then"})," the publisher node successfully broadcasts messages."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Given"})," a ROS 2 environment is set up, ",(0,o.jsx)(n.strong,{children:"When"})," the user follows the tutorial for creating a subscriber node, ",(0,o.jsx)(n.strong,{children:"Then"})," the subscriber node successfully receives messages from the publisher."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Given"})," a ROS 2 environment is set up, ",(0,o.jsx)(n.strong,{children:"When"})," the user implements a simple ROS 2 service client and server, ",(0,o.jsx)(n.strong,{children:"Then"})," the client successfully calls the service and receives a response."]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h3,{id:"module-2---simulate-humanoid-robots-priority-p1",children:"Module 2 - Simulate Humanoid Robots (Priority: P1)"}),"\n",(0,o.jsx)(n.p,{children:"Gain proficiency in using Gazebo and Unity to create and simulate humanoid robot models, understanding physics, sensors, and environment interactions."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Why this priority"}),": Simulation is a critical tool for developing and testing robotics applications without real hardware."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Independent Test"}),": User can load a humanoid robot model into Gazebo/Unity and observe its behavior under simulated physics."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Acceptance Scenarios"}),":"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Given"})," Gazebo/Unity is installed, ",(0,o.jsx)(n.strong,{children:"When"})," the user loads a provided humanoid robot model, ",(0,o.jsx)(n.strong,{children:"Then"})," the robot model appears correctly in the simulation environment."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Given"})," a humanoid robot model is loaded, ",(0,o.jsx)(n.strong,{children:"When"})," the user applies simulated forces or commands, ",(0,o.jsx)(n.strong,{children:"Then"})," the robot's joints move realistically according to physics."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Given"})," a humanoid robot model is loaded, ",(0,o.jsx)(n.strong,{children:"When"})," the user configures simulated sensors (e.g., camera, lidar), ",(0,o.jsx)(n.strong,{children:"Then"})," sensor data is accurately generated and accessible."]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h3,{id:"module-3---develop-ai-robot-brain-in-nvidia-isaac-priority-p2",children:"Module 3 - Develop AI-Robot Brain in NVIDIA Isaac (Priority: P2)"}),"\n",(0,o.jsx)(n.p,{children:"Learn to develop perception, navigation, and manipulation pipelines for humanoid robots using the NVIDIA Isaac platform, focusing on AI capabilities."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Why this priority"}),": NVIDIA Isaac provides advanced tools for AI-driven robotics, essential for building intelligent humanoid behaviors."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Independent Test"}),": User can implement a basic perception pipeline in Isaac that detects objects in a simulated environment."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Acceptance Scenarios"}),":"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Given"})," NVIDIA Isaac environment is set up with a simulated robot, ",(0,o.jsx)(n.strong,{children:"When"})," the user implements an object detection pipeline, ",(0,o.jsx)(n.strong,{children:"Then"})," the pipeline correctly identifies and localizes objects in the simulated scene."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Given"})," an object detection pipeline, ",(0,o.jsx)(n.strong,{children:"When"})," the user integrates a navigation algorithm, ",(0,o.jsx)(n.strong,{children:"Then"})," the robot can autonomously navigate to a target location while avoiding obstacles."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Given"})," a navigation pipeline, ",(0,o.jsx)(n.strong,{children:"When"})," the user implements a manipulation task (e.g., pick-and-place), ",(0,o.jsx)(n.strong,{children:"Then"})," the robot successfully grasps and moves an object."]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h3,{id:"module-4---integrate-llms-for-vla-priority-p2",children:"Module 4 - Integrate LLMs for VLA (Priority: P2)"}),"\n",(0,o.jsx)(n.p,{children:"Understand how to integrate Large Language Models (LLMs) with robotics for voice-command interfaces and advanced task planning, enabling Vision-Language-Action (VLA) capabilities."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Why this priority"}),": LLM integration represents a cutting-edge approach to human-robot interaction and complex task execution."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Independent Test"}),": User can issue a voice command to a simulated robot and observe the robot interpreting and executing a simple task."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Acceptance Scenarios"}),":"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Given"})," an LLM and Whisper integration with a simulated robot, ",(0,o.jsx)(n.strong,{children:"When"}),' the user issues a voice command (e.g., "pick up the red cube"), ',(0,o.jsx)(n.strong,{children:"Then"})," the system correctly transcribes the command and the LLM generates a relevant action plan."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Given"})," an action plan, ",(0,o.jsx)(n.strong,{children:"When"})," the robot executes the plan using its manipulation capabilities, ",(0,o.jsx)(n.strong,{children:"Then"})," the robot performs the desired action (e.g., picking up the red cube)."]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h3,{id:"module-5---build-autonomous-simulated-humanoid-priority-p3",children:"Module 5 - Build Autonomous Simulated Humanoid (Priority: P3)"}),"\n",(0,o.jsx)(n.p,{children:"Apply knowledge from all modules to develop a fully autonomous simulated humanoid robot as a capstone project, demonstrating integrated intelligence."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Why this priority"}),": The capstone project allows for synthesis of all learned concepts into a complete system."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Independent Test"}),": The simulated humanoid can autonomously perform a complex multi-step task based on high-level goals."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Acceptance Scenarios"}),":"]}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Given"})," all previous modules are completed, ",(0,o.jsx)(n.strong,{children:"When"})," the user integrates all components into a simulated humanoid, ",(0,o.jsx)(n.strong,{children:"Then"})," the humanoid demonstrates autonomous behavior based on a defined set of high-level goals."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Given"})," autonomous operation, ",(0,o.jsx)(n.strong,{children:"When"})," the user introduces unforeseen environmental changes, ",(0,o.jsx)(n.strong,{children:"Then"})," the humanoid adapts its behavior to successfully complete its task."]}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h3,{id:"edge-cases",children:"Edge Cases"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"What happens when sensor data is noisy or incomplete?"}),"\n",(0,o.jsx)(n.li,{children:"How does the system handle communication failures between ROS 2 nodes?"}),"\n",(0,o.jsx)(n.li,{children:"What are the limitations of physics simulation fidelity in Gazebo/Unity?"}),"\n",(0,o.jsx)(n.li,{children:"How does the LLM handle ambiguous or out-of-domain voice commands?"}),"\n",(0,o.jsx)(n.li,{children:"What happens when a manipulation task fails due to an unexpected object configuration?"}),"\n"]}),"\n",(0,o.jsxs)(n.h2,{id:"requirements-mandatory",children:["Requirements ",(0,o.jsx)(n.em,{children:"(mandatory)"})]}),"\n",(0,o.jsx)(n.h3,{id:"functional-requirements",children:"Functional Requirements"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-001"}),": The textbook MUST cover ROS 2 architecture, nodes, topics, and services."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-002"}),": The textbook MUST provide guidance on simulating humanoid robots using Gazebo."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-003"}),": The textbook MUST provide guidance on simulating humanoid robots using Unity."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-004"}),": The textbook MUST cover development of perception pipelines in NVIDIA Isaac."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-005"}),": The textbook MUST cover development of navigation pipelines in NVIDIA Isaac."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-006"}),": The textbook MUST cover development of manipulation pipelines in NVIDIA Isaac."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-007"}),": The textbook MUST explain the integration of LLMs for voice-command functionality in robotics."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-008"}),": The textbook MUST explain the integration of LLMs for task planning in robotics."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-009"}),": The textbook MUST include content on embodied AI principles."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-010"}),": The textbook MUST include content on human-robot interaction."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-011"}),": The textbook MUST include hands-on projects and a capstone development guide for building an autonomous simulated humanoid."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-012"}),": The textbook MUST ensure accurate simulation examples with physics and sensor fidelity."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-013"}),": The textbook MUST provide examples of realistic perception and navigation pipelines."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-014"}),": The textbook MUST discuss hardware-software co-design for edge deployment (e.g., Jetson Orin)."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-015"}),": The textbook's code examples and exercises MUST be reproducible on local or cloud workstations."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-016"}),": The textbook MUST adhere to an iterative, hypothesis-driven research and development workflow in its content presentation."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-017"}),": All AI techniques and claims presented in the textbook MUST be supported by peer-reviewed references."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-018"}),": Knowledge transfer and documentation MUST be embedded within the textbook content."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-019"}),": The textbook MUST incorporate continuous integration principles for simulation, real-world testing, and feedback loops in its examples."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-020"}),": The textbook MUST include specific guidance on handling security vulnerabilities and ethical challenges in implementations."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"FR-021"}),": The textbook MUST include specific examples and case studies to illustrate ethical dilemmas and safety protocols."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"clarifications",children:"Clarifications"}),"\n",(0,o.jsx)(n.h3,{id:"session-2025-12-05",children:"Session 2025-12-05"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Q: Should the textbook provide specific guidance on handling security vulnerabilities and ethical challenges in implementations, beyond conceptual discussions? \u2192 A: Yes, include specific guidance on handling security vulnerabilities and ethical challenges in implementations."}),"\n",(0,o.jsx)(n.li,{children:"Q: Should the textbook include specific examples and case studies to illustrate ethical dilemmas and safety protocols? \u2192 A: Yes, include specific examples and case studies to illustrate ethical dilemmas and safety protocols."}),"\n"]}),"\n",(0,o.jsxs)(n.h3,{id:"key-entities-include-if-feature-involves-data",children:["Key Entities ",(0,o.jsx)(n.em,{children:"(include if feature involves data)"})]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Robot Model"}),": Representation of a physical humanoid robot in simulation."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"ROS 2 Node"}),": Independent executable processing unit in ROS 2."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Simulation Environment"}),": Gazebo, Unity."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Perception Pipeline"}),": Components for processing sensor data to understand the environment."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Navigation Pipeline"}),": Components for path planning and movement control."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Manipulation Pipeline"}),": Components for robotic arm/hand control for object interaction."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"LLM (Large Language Model)"}),": AI model for natural language understanding and generation."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"VLA (Vision-Language-Action)"}),": Framework integrating visual perception, language understanding, and robotic actions."]}),"\n"]}),"\n",(0,o.jsxs)(n.h2,{id:"success-criteria-mandatory",children:["Success Criteria ",(0,o.jsx)(n.em,{children:"(mandatory)"})]}),"\n",(0,o.jsx)(n.h3,{id:"measurable-outcomes",children:"Measurable Outcomes"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"SC-001"}),": Each module contains practical exercises and code examples that are verifiable and runnable."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"SC-002"}),": The capstone project successfully demonstrates the integration of all learned modules into an autonomous humanoid robot simulation."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"SC-003"}),": All technical claims are supported by verifiable sources, with at least 50% being peer-reviewed."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"SC-004"}),": The generated Docusaurus site builds cleanly and is deployable on GitHub Pages."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"SC-005"}),": The final PDF output includes correctly embedded APA-style citations and a reference list."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"SC-006"}),": The textbook meets the Flesch-Kincaid grade level of 10-12 and demonstrates zero plagiarism."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}}}]);